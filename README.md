# arman-to-longformer
This project use Longformer's attention mechanism to [alireza7/ARMAN-MSR-persian-base](https://huggingface.co/alireza7/ARMAN-MSR-persian-base) in order to perform abstractive summarization on long documents. so new model can accept 8K tokens (rather than 512 tokens).it should be fine-tuned for summarization tasks.

converted model is available in [huggingface](https://huggingface.co/zedfum/arman-longformer-8k)
